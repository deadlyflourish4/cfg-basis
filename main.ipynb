{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1a. Rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = \"data/\"\n",
    "output_path = \"output/grammar.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NP -&gt; ART N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NP -&gt; ART ADJ N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NP -&gt; ART N PP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NP -&gt; ART ADJ ADJ N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NP -&gt; DET N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Unnamed: 0\n",
       "0          NP -> ART N\n",
       "1      NP -> ART ADJ N\n",
       "2       NP -> ART N PP\n",
       "3  NP -> ART ADJ ADJ N\n",
       "4          NP -> DET N"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_grammar = pd.read_excel(f\"{input_path}/sample_grammar_rules.xlsx\")\n",
    "df_grammar.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thư mục hiện tại: d:\\HCMUT\\241\\CO3085_NLP\\assignment1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"Thư mục hiện tại:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_directory = 'output'\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "output_path = os.path.join(output_directory, 'grammar.txt')\n",
    "\n",
    "with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        for index, row in df_grammar.iterrows():\n",
    "            line = ', '.join(str(value) for value in row) \n",
    "            f.write(line + '\\n')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_grammar_format(input_file, output_file):\n",
    "    with open(input_file, 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    converted_rules = {}\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        lhs, rhs = line.split('->')\n",
    "        lhs = lhs.strip()\n",
    "        rhs_parts = rhs.strip().split()\n",
    "\n",
    "        if lhs in converted_rules:\n",
    "            converted_rules[lhs].append(rhs_parts)\n",
    "        else:\n",
    "            converted_rules[lhs] = [rhs_parts]\n",
    "\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        for key, value in converted_rules.items():\n",
    "            f.write(f\"'{key}': {value},\\n\")\n",
    "\n",
    "input_file = \"output/grammar.txt\"  # Tên file đầu vào\n",
    "output_file = \"output/output.txt\"  # Tên file đầu ra\n",
    "convert_grammar_format(input_file, output_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lexicon "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ART -&gt; the | a | an</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ADJ -&gt; happy | busy | interested | great | neg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>N -&gt; customer | service | product | call | res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>V -&gt; call | offer | want | need | say | respon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P -&gt; to | for | in | on | with | about | at</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Unnamed: 0\n",
       "0                                ART -> the | a | an\n",
       "1  ADJ -> happy | busy | interested | great | neg...\n",
       "2  N -> customer | service | product | call | res...\n",
       "3  V -> call | offer | want | need | say | respon...\n",
       "4        P -> to | for | in | on | with | about | at"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lexicon = pd.read_excel(f\"data/sample_lexicon.xlsx\")\n",
    "df_lexicon.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = os.path.join(output_directory, 'lexicon.txt')\n",
    "\n",
    "with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        for index, row in df_lexicon.iterrows():\n",
    "            line = ', '.join(str(value) for value in row) \n",
    "            f.write(line + '\\n')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_lexicon_format(input_file, output_file):\n",
    "    with open(input_file, 'r', encoding='utf-8') as f:\n",
    "        rules = f.readlines()\n",
    "    \n",
    "    converted_lexicons = {}\n",
    "    for rule in rules:\n",
    "        lhs, rhs = rule.split('->')\n",
    "        lhs = lhs.strip()\n",
    "        rhs = rhs.strip()\n",
    "\n",
    "        rhs_dict = [item.strip() for item in rhs.split('|')]\n",
    "        \n",
    "        if lhs not in converted_lexicons:\n",
    "                    converted_lexicons[lhs] = []\n",
    "        \n",
    "        # Bao bọc mỗi item trong một danh sách\n",
    "        for item in rhs_dict:\n",
    "            item = [item]  # Bao bọc item trong một danh sách\n",
    "            converted_lexicons[lhs].append(item)\n",
    "        \n",
    "        \n",
    "    \n",
    "    with open(output_file, 'a', encoding='utf-8') as f:\n",
    "        for key, value in converted_lexicons.items():\n",
    "            f.write(f\"'{key}': {value},\\n\")\n",
    "\n",
    "\n",
    "input_file = \"output/lexicon.txt\"  # Tên file đầu vào\n",
    "output_file = \"output/output.txt\"  # Tên file đầu ra\n",
    "convert_lexicon_format(input_file, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sinh câu:\n",
      "the cat liked the treat in the dog by the treat in a cat on a cat on a dog in a cat on the treat in a cat in a treat by the cat on a treat on a cat in the cat on the cat in a cat in the dog by a dog in a cat in a dog in a dog on a dog by a cat on the treat on a cat by the cat in a cat on a cat on the dog in the cat in a treat\n",
      "a treat saw the cat in the cat\n",
      "a cat saw a treat\n",
      "the dog in the treat saw a cat\n",
      "a cat chased a dog\n",
      "\n",
      "Phân tích cú pháp câu:\n",
      "Câu 'the dog chased a cat' không hợp lệ.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Định nghĩa ngữ pháp bằng từ điển\n",
    "grammar = {\n",
    "    'S': [['NP', 'VP']],\n",
    "    'NP': [['Det', 'N'], ['Det', 'N', 'PP']],\n",
    "    'VP': [['V', 'NP'], ['VP', 'PP']],\n",
    "    'PP': [['P', 'NP']],\n",
    "    'Det': [['the'], ['a']],\n",
    "    'N': [['dog'], ['cat'], ['treat']],\n",
    "    'V': [['chased'], ['saw'], ['liked']],\n",
    "    'P': [['in'], ['on'], ['by']],\n",
    "}\n",
    "\n",
    "# Hàm sinh câu từ ngữ pháp\n",
    "def generate_sentence(symbol):\n",
    "    if symbol not in grammar:\n",
    "        return symbol  # Nếu là ký hiệu terminal, trả về ngay\n",
    "    \n",
    "    production = random.choice(grammar[symbol])  # Chọn một quy tắc sản xuất ngẫu nhiên\n",
    "    result = []\n",
    "    for part in production:\n",
    "        result.append(generate_sentence(part))  # Đệ quy cho mỗi phần\n",
    "    return ' '.join(result)  # Kết hợp các phần lại thành một câu\n",
    "\n",
    "# Hàm phân tích cú pháp\n",
    "def parse_sentence(sentence):\n",
    "    words = sentence.split()\n",
    "    return parse_helper(words, 'S')\n",
    "\n",
    "def parse_helper(words, symbol):\n",
    "    if not words:\n",
    "        return False\n",
    "    \n",
    "    if symbol not in grammar:\n",
    "        if words[0] == symbol:\n",
    "            return words[1:]  # Trả về danh sách từ còn lại\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    for production in grammar[symbol]:\n",
    "        remaining_words = words\n",
    "        for part in production:\n",
    "            remaining_words = parse_helper(remaining_words, part)\n",
    "            if remaining_words is False:\n",
    "                break\n",
    "        if remaining_words is not False:\n",
    "            return remaining_words  # Trả về danh sách từ còn lại\n",
    "\n",
    "    return False\n",
    "\n",
    "# Ví dụ sử dụng\n",
    "print(\"Sinh câu:\")\n",
    "for _ in range(5):\n",
    "    print(generate_sentence('S'))\n",
    "\n",
    "print(\"\\nPhân tích cú pháp câu:\")\n",
    "sentence = \"the dog chased a cat\"\n",
    "if parse_sentence(sentence):\n",
    "    print(f\"Câu '{sentence}' được phân tích cú pháp thành công.\")\n",
    "else:\n",
    "    print(f\"Câu '{sentence}' không hợp lệ.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1b. Sentences generation algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar_rule = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'NP': [['ART', 'N'], ['ART', 'ADJ', 'N'], ['ART', 'N', 'PP'], ['ART', 'ADJ', 'ADJ', 'N'], ['DET', 'N'], ['PRON'], ['QUANT', 'N'], ['QUANT', 'ADJ', 'N'], ['NP', 'P', 'NP'], ['NP', 'CONJ', 'NP'], ['NP', 'PP'], ['PRON', 'P', 'NP'], ['DET', 'ADJ', 'N', 'PP'], ['DET', 'N', 'POS', 'N'], ['PRON', 'POS', 'N'], ['NUM', 'N'], ['NP', 'REL', 'S'], ['ART', 'ADV', 'ADJ', 'N'], ['ADV', 'ADJ', 'N'], ['DET', 'ADV', 'ADJ', 'N']], 'VP': [['V'], ['V', 'NP'], ['V', 'PP'], ['V', 'ADV'], ['MOD', 'V'], ['AUX', 'NEG', 'V'], ['V', 'CONJ', 'V'], ['V', 'S'], ['ADV', 'VP']], 'ADJP': [['ADJ'], ['ADV', 'ADJ'], ['ADJ', 'CONJ', 'ADJ'], ['ADJ', 'PP']], 'ADV': [['quickly'], ['eagerly'], ['positively'], ['negatively'], ['always'], ['never']], 'PP': [['P', 'NP'], ['P', 'PRON'], ['P', 'ADJP'], ['PP', 'CONJ', 'PP'], ['P', 'ADV']], 'S': [['NP', 'VP'], ['NP', 'VP', 'PP'], ['NP', 'VP', 'ADJP'], ['NP', 'VP', 'CONJ', 'S'], ['S', 'CONJ', 'S'], ['S', 'ADJP']], 'QP': [['Q', 'AUX', 'NP'], ['Q', 'V', 'NP']], 'ART': [['the'], ['a'], ['an']], 'ADJ': [['happy'], ['busy'], ['interested'], ['great'], ['negative'], ['positive'], ['new'], ['old']], 'N': [['customer'], ['service'], ['product'], ['call'], ['response'], ['need'], ['time'], ['company']], 'V': [['call'], ['offer'], ['want'], ['need'], ['say'], ['respond'], ['reject'], ['accept']], 'P': [['to'], ['for'], ['in'], ['on'], ['with'], ['about'], ['at']], 'PRON': [['I'], ['you'], ['he'], ['she'], ['we'], ['they'], ['it']], 'NUM': [['one'], ['two'], ['three'], ['many'], ['few']], 'POS': [['my'], ['your'], ['his'], ['her'], ['their']], 'QUANT': [['some'], ['any'], ['all'], ['most']], 'CONJ': [['and'], ['or'], ['but'], ['because'], ['although']], 'MOD': [['can'], ['may'], ['must'], ['should']], 'AUX': [['is'], ['are'], ['was'], ['have'], ['do']], 'NEG': [['not'], ['no']], 'REL': [['who'], ['that'], ['which']], 'DET': [['this'], ['that'], ['these'], ['those']]}\n"
     ]
    }
   ],
   "source": [
    "with open(\"output/output.txt\", 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        key, value = line.strip().split(': ')\n",
    "        key = key.strip(\"'\")  \n",
    "        value = ast.literal_eval(value.strip(','))\n",
    "        \n",
    "        grammar_rule[key] = value\n",
    "\n",
    "print(grammar_rule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sentence(symbol):\n",
    "    if symbol not in grammar_rule:\n",
    "        return symbol\n",
    "    \n",
    "    result = []\n",
    "    prods = random.choice(grammar_rule[symbol])\n",
    "    for prod in prods:\n",
    "        result.append(generate_sentence(prod))\n",
    "    return ' '.join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_directory = 'output'\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "output_path = os.path.join(output_directory, 'samples.txt')\n",
    "with open(\"output/sample.txt\", 'w', encoding='utf-8') as file:\n",
    "    for _ in range(10000):\n",
    "        sentence = generate_sentence('S')\n",
    "        file.write(f\"{sentence}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
